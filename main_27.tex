\documentclass{article}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\usepackage[utf8]{inputenc}

\title{Assignment 27}
\author{Xiaoting Li (xil139) \\
Ziyu Zhang (ziz41) \\
Deniz Unal (des204)}
\date{March 29 2019}

\begin{document}
\maketitle
\noindent
\textbf{45 - 46. In the Vertex Cover Decision problem (VCD) the input is a graph $G$ and an integer $k$, and the output is 1 if G has a vertex cover of size $k$, and 0 otherwise. In the Vertex Cover Optimization problem (VCO) the input is a graph $G$, and the output is a minimum cardinality vertex cover of $G$.} \\ \newline
\textbf{(a) Show that if VCD has a polynomial time algorithm, then VCO has a polynomial time algorithm.} \\ \newline
Answer: We assume that we have a poly time solution for VCD. We can start with $k =$ number of vertices in $G$. Then we would run our algorithm for VCD recursively to see if there's a vertex cover of size $k$. We would decrement $k$ and continue for each value of $k$ until it is 0. The smallest value of $k$ that would output 1 (there is a vertex cover of size $k$) from VCD would be the size of min cardinality vertex cover in $G$. We implement another algorithm based on VCD, whenever it would output a 1, instead, it would return the set of vertices picked (This is stil poly time because VCD is poly time). Then we would just run this algorithm with the size of min cardinality vertex cover found from VCD and so it would return the set of vertices picked. This is the output needed for VCO. So, if we can have a poly time solution for VCD we also have a poly time solution for VCO.\\ \newline
\textbf{(b) Show that if VCD has a fixed parameter tractable algorithm in the parameter $k$, then VCO has a fixed parameter tractable algorithm in the parameter $\ell$, which is the cardinality of the minimum vertex cover.} \\ \newline
Answer: We can re-formulate VCO as a decision problem and call this $VCO_d$: ``Is there a vertex cover of size less than $\ell$''.  If we have a fixed parameter tractable algorithm for the decision problem VCD in the parameter $k$, we should have fixed parameter tractable algorithm for $VCO_d$ in the parameter $\ell$. Since $VCO_d$ is equivalent to the original optimization problem VCO, we can say that VCO has a fixed parameter tractable algorithm in the parameter $\ell$ if VCD has a fixed parameter tractable algorithm in the parameter $k$.\\ \newline
\textbf{47. Problem 35-1 parts a through e from CLRS text} \\ \newline
\textbf{a.}Answer: 
The partition problem is defined as given numbers of $s_1, s_2, ... s_n$, is there any partition of them that sum of both group is equal to $(\sum_{i=1}^{n} s_i)/2$. Given the input of partition problem, we could build a bin packing with same numbers $s_1, s_2, ... s_n$, with 2 bins of size of $(\sum_{i=1}^{n} s_i)/2$.
\\ \newline
\textbf{b.}Answer: 
If the min of optimal number of bins is less than  $\ceil*{S}$, even if it is  $\ceil*{S} - 1$, the total number of things bins could hold would be less or equal to
$\ceil*{S} - 1$ which is less than $S$, so it must be at least $\ceil*{S}$.
\\ \newline
\textbf{c.}Answer:
We only focus on $s$ where $s\leq1/2$, since the rest of $s$ will not create bins that is less than half full. Suppose $s_i, s_{i+1} ... s_{i+k}$ are all elements that is less than size of half. When we deal with $s_i$ which is the 1st element that is less than half, we create the 1st bin that is less than half full. However, when we deal with the following elements, we will either put in to the 1st bin that is less than half full, or when 1st bin exceed half full, we create the 2nd bin that is less than half full. For both cases, there would be only one bin that is less than half full.
\\ \newline
\textbf{d.}Answer:
If the number of bins is more than $\ceil*{2S}$, suppose it is $\ceil*{2S}+1$. From c, we know that the at most one of them is less than half full, so the total size stored in bins would be at least $(\ceil*{2S} +1 - 1)/2 + size_{the bin less than half full} $ which will be more than $S$.
\\ \newline
\textbf{e.}
Since number of bins is never more than $\ceil*{2S}$, we know the first-fit is an approximation ratio of 2.
\\ \newline
\textbf{48. Problem 35-5 parts a, b and d from the CLRS text} \\ \newline
\textbf{a.}
Answer: The optimal makespan is when each job has their own machine. Then the makespan is as large as the greatest processing time since each job has to run consecutive time on a machine. So we can say that $C_{max}^{*} \geq max_{1\leq k \leq n}p_k$.\\ \newline
\textbf{b.}
Answer: When all of the jobs can be evenly distributed on all machines, all machines stop working at the same time. The makespan is optimal in this case. If jobs are not evenly distributed, the time it takes for the last machine to stop would increase, which is higher than the optimal makespan. So we can say the optimal span is the average time of the time that it takes for all jobs to finish, which is $C_{max}^{*} \geq \frac{1}{m} \sum_{1\leq k \leq n}p_k$. \\ \newline
\textbf{c.}
Answer: Let's say we have $l_k$ which denotes the time when machine $M_k$ finishes one job and can start to work on the next job (when machine is available). The greedy algorithm always assigns the next job to the first available machine. So we have $C_{max} \leq min_{m\in[1, m]}l_{mk} + p_j$, $min_{m\in[1, m]}$, in which $l_{mk}$ is the longest time for a machine to become available and $p_j$ is the time to finish executing job $j$. From (a) and (b), we learn that $C_{max}^{*} \geq max_{1\leq k \leq n}p_k$ and $C_{max}^{*} \geq \frac{1}{m} \sum_{1\leq k \leq n}p_k$, and we have $p_j \leq max_{1\leq k \leq n}p_k$, so we have $C_{max} \leq max_{1\leq k \leq n}p_k + max_{1\leq k \leq n}p_k$. Since both of $max_{1\leq k \leq n}p_k$ and $max_{1\leq k \leq n}p_k$ are smaller or equal to $C_{max}^{*}$, we can say $C_{max} \leq 2\cdot C_{max}^{*}$. It means the greedy algorithm is polynomial-time 2-approximation algorithm.
\end{document}
