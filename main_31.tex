\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Assignment 31}
\author{Xiaoting Li (xil139) \\
Ziyu Zhang (ziz41) \\
Deniz Unal (des204)}
\date{April 8 2019}

\begin{document}
\maketitle
\noindent
\textbf{56. Consider an online or approximation problem where there are only finitely many possible algorithms and finitely many possible inputs. We generalize Yao’s technique to approximation ratios. The correct answer is ”yes” to three of the following four questions, and the correct answer is ”no” for the remaining question. Identify the three questions where the answer is yes, and give a proof that the answer is yes.} \\ \newline
\textbf{(a) Assume that the problem is a minimization problem} \\ \newline
Answer: 1) i is correct if the problem is a minimization problem. Let $A$ be a deterministic algorithm, $a$ be a randomized algorithm, $i$ be a generic input, and $I$ be an input distribution. Using Yao's technique, we learn that $min_a max_I E[a(I)] \geq max_I min_A E[A(I)]$. From i, we learn that $E[A(I)]/E[OPT(I)] \geq c$. So we have $min_a max_I E[a(I)]/E[OPT(I)] \geq max_I min_A E[A(I)]/E[OPT(I) \geq c$. So we can say that the expected competitive ratio for every randomized algorithm is at least $c$. \\ \newline
2) ii. is correct. From the question text we know that given an input distribution $I$, for all deterministic algorithms $A$, we know that $E[A(I) / Opt(I)] \geq c$. We can also say that under the worst input distribution this would still hold as the ratio will be higher then when the input distribution is $I$. Thus we have, $max_I E[A(I) / Opt(I)] \geq c$. Since this holds for every deterministic algorithm we can also say that $min_A max_I E[A(I) / Opt(I)] \geq c$. Then using Yao's technique we can conclude that $min_a max_I E[a(I) / Opt(I)] \geq c$. So, the expected competitive ratio for every randomized algorithm is also at least $c$. \\ \newline
\textbf{(b) Assume that the problem is a maximization problem} \\ \newline
Answer: i. is correct. From the question text we know that given an input distribution $I$, for all deterministic algorithms $A$, we know that $E[Opt(I)] / E[A(I)] \geq c$. First we re-write the formula as $E[A(I)] \leq E[Opt(I)] / c$. We know that this is true for every deterministic algorithm, then we can say that $max_A E[A(I)] \leq E[Opt(I)] / c$. By Yao's technique we have $max_a min_I E[a(I)] \leq max_A E[A(I)]$. Since $max_A E[A(I)] \leq E[Opt(I)] / c$, we also have $max_a min_I E[a(I)] \leq E[Opt(I)] / c = max_a min_I E[a(I)] / E[Opt(I)] \leq 1 / c$ which implies $max_a min_I E[Opt(I)] / E[a(I)] \geq c$. Then we can say if the worst randomized algorithm's expected competitive tatio is at least $c$ then every randomized algorithm has competitive ratio at least $c$. \\ \newline
ii. The answer is no for this question. \\ \newline
\textbf{57. Show that the expected competitive ratio for every randomized paging algorithms is
$\Omega(logk)$.}\\ \newline
Answer: Let's denote $k$ as the size of fast memory, $n = k + 1$ as the number of pages. Given an adversarial strategy that request a page uniformly random at each step, the probability of a page fault is $prob(miss) = \frac{1}{k + 1}$. Let $m$ be the number of requests. The expected number of requests is $E[m] = \sum_{i=1}^{n}\frac{1}{n-i+1} = \theta(nlogn)$. So the expected cost of a randomized paging algorithm is $E[A] = \frac{1}{k+1} \cdot nlogn = \frac{1}{k+ 1}\cdot (k+1)log(k+1) = log(k+1)$. So the expected competitive ratio for every randomized paging algorithms is $\Omega(logk)$.

\end{document}
