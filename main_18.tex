\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}

\title{Assignment 18}
\author{Xiaoting Li (xil139) \\
Ziyu Zhang (ziz41) \\
Deniz Unal (des204)}
\date{March 1, 2019}

\begin{document}

\maketitle

\noindent
\textbf{29. 11-2 from CLRS.}\\ \newline
\textbf{a.} In order to have exactly $k$ keys hash to a particular slot, we need to pick $k$ keys from $n$ keys. The probability of a key being hashed into a particular slot is $\frac{1}{n}$ and the probability of a key not being hashed into a particular slot is $1 - \frac{1}{n}$. So the probability $Q_k$ that exactly k keys hash to a particular slot is $\big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\big(_k^n)$. \\ \newline 
\textbf{b.} Let $X_i$ be the number of keys that are hashed to slot $i$, $i = 1, 2, 3, ..., n$. So we have $P_k = Prob(M = k)$. Since $M$ is the maximum number of keys in any slot after all the keys have been inserted. We have $$P_k = Prob(M = k) \leq Prob[U_{i=1}^{n}X_i = k] = \sum_{i=1}^{n}Prob[U_{i=1}^{n}X_i = k]$$
From (a) we know that $Q_k = \big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\big(_k^n)$. So we plug this into the equation above and we can get $P_k \leq nQ_k$. \\ \newline
\textbf{c.} We can rewrite $Q_k$ as $\big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\frac{n!}{k!(n-k)!}$. Since $\frac{1}{n})^{n-k}$ is smaller than one, we get $$\big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\frac{n!}{k!(n-k)!} \leq \big(\frac{1}{n})^k \frac{n!}{k!(n-k)!}$$
Since the weak upper bound on the factorial function is $n! \leq n^n$, we can rewrite the equation above as: $$\big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\frac{n!}{k!(n-k)!} \leq \frac{n^{n-k}}{k!(n - k)!}$$
Since $n^{n-k}$ is larger than $(n - k)!$, we get $$\big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\frac{n!}{k!(n-k)!} \leq \frac{1}{k!}$$
Using Stirling Approximation, we learn that $n! = \sqrt{2\pi n}\big(\frac{n}{e})^n e^{\alpha_n}$. So we can say $k! > \big(\frac{k}{e})^k$. Plug this into the equation above, we get 
$$Q_k = \big(\frac{1}{n})^k\big(1 - \frac{1}{n})^{n-k}\frac{n!}{k!(n-k)!} \leq \frac{1}{k!} < e^k/k^k$$
\textbf{d.} From part (c), we know that $Q_k < e^k/k^k$ So we need to show that $e^{k_0}/{k_0}^{k_0} < 1/n^3$, or $n^3 < {k_0}^{k_0}/e^{k_0}$. If we take the logarithm of both sides we get, 
\begin{align*}
3lgn < k_0(lgk_0 - lge) = \frac {clgn}{lglgn}(lgc + lglgn - lglglgn - lge).
\end{align*}
If we divide both sides by lgn, we get, 
\begin{align*}
3 &< \frac{c}{\lg\lg n}(\lg c + \lg\lg n - \lg\lg\lg n - \lg e) \\
&= c(1 + \frac{\lg c - \lg e}{\lg\lg n} - \frac{\lg\lg\lg n}{\lg\lg n}).
\end{align*}
 Let x be $(1 + \frac{\lg c - \lg e}{\lg\lg n} - \frac{\lg\lg\lg n}{\lg\lg n})$. We need to show that there exists a $c > 1$ such that $3 < cx$. As n goes to infinity, logarithmic terms inside of $x$ will be zeroed out and $x$ will be 1. Therefore minimum $c$ value that satisfies this inequality will be 4 so it is our lower bound for $c$. Let $c_i$ be the value that satisfies the inequality for $n = i$. Then c will be the max of $c_i$ and 4. \\
In subproblem (b) we showed that $P_k \leq nQ_{k_0}$ and from this step we could show $Q_{k_0} < 1/n^3$. So, $nQ_{k_0} < n/n^3 = 1/n^2$. Then $P_k < 1/n^2$ for all $k \geq k_0$ as $Q_k$ is a decreasing function of k.  \\ \newline
\textbf{e.} We have the expected value of $M$ as 
$E[M] = \sum_{k=0}^nk\cdot Prob(M = k)$. So we have 
$$E[M] = \sum_{k=0}^nk\cdot Prob(M = k) = \sum_{k = 0}^{k_{0}}k\cdot Prob(M = k) + \sum_{k = k_0+1}^nk\cdot Prob(M = k)$$
Then we have 
\begin{align*}
&E[M]=\sum_{k = 0}^{k_{0}}k\cdot Prob(M = k) + \sum_{k = k_0+1}^nk\cdot Prob(M = k) \\
&\leq \sum_{k = 0}^{k_{0}}k_0\cdot Prob(M = k) + n\sum_{k = k_0+1}^nProb(M = k)\\
&= k_0\sum_{k = 0}^{k_{0}}Prob(M = k) + n\sum_{k = k_0+1}^nProb(M = k)\\
&\leq k_0Prob(M \leq k_0) + nProb(M > k_0)\\
&= Prob(M > \frac{clgn}{lglgn})\cdot n + Prob(M\leq \frac{clgn}{lglgn})\cdot \frac{clgn}{lglgn}
\end{align*}
In (d) we learn that $P_k < 1/n^2$ for $k \geq k_0 = clgn/lglgn$. So we have
\begin{align*}
&\sum_{k = k_0+1}^nProb(M = k) \\
&=\sum_{k = k_0+1}^nP_k \\
&< \sum_{k = k_0+1}^n1/n^2 \\
&< n\cdot 1/n^2\\
&=1/n
\end{align*}
So we can rewrite $E[M]$ as $E]M] < k_0 \cdot 1 + n\cdot 1/n = O(lgn/lglgn)$
\end{document}
